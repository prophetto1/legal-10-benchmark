<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Adding New Scenarios - Legal-10 Benchmark</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link href="../docstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Adding New Scenarios";
        var mkdocs_page_input_path = "adding_new_scenarios.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]--> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Legal-10 Benchmark
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Home</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="..">Legal-10 Benchmark</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../notes/">Legal-10 Development Notes</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">SKILLSETS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_1_research_planning/">Skill 1: Research Planning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_2_strategic_stopping/">Skill 2: Strategic Stopping</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_3_known_authority/">Skill 3: Known Authority</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_4_unknown_authority/">Skill 4: Unknown Authority</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_5_validate_authority/">Skill 5: Validate Authority</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_6_fact_extraction/">Skill 6: Fact Extraction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_7_distinguish_cases/">Skill 7: Distinguish Cases</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_8_synthesize_results/">Skill 8: Synthesize Results</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_9_citation_integrity/">Skill 9: Citation Integrity</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../skill_10_copyright_compliance/">Skill 10: Copyright Compliance</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">EXTENSIONS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../extension_multilingual/">Multilingual</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">User Guide</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../quick_start/">Quick Start</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../tutorial/">Tutorial</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../run_entries_configuration_files/">Run Entries Configuration Files</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../run_entries/">Run Entries</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../credentials/">Credentials</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../importing_custom_modules/">Importing Custom Modules</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../adding_new_models/">Adding New Models</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Adding New Scenarios</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../benchmark/">Advanced Benchmarking Guide</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Developer Guide</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../developer_setup/">Developer Setup</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../architecture_assessment/">HELM Framework Architectural Assessment for Legal-10 Integration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../developer_adding_new_models/">Adding New Clients</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../editing_documentation/">Editing Documentation</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Legal-10 Benchmark</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">User Guide</li>
      <li class="breadcrumb-item active">Adding New Scenarios</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/prophetto1/legal-10-benchmark/blob/main/docs/adding_new_scenarios.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="adding-new-scenarios">Adding New Scenarios</h1>
<p>HELM comes with more than a hundred built-in scenarios. However, you may want to run HELM on a scenario that is not built into HELM yet, or you may want to run HELM on scenarios that use your private datasets. Because HELM is a modular framework with a plug-in architecture, you can run evaluations with your custom scenarios on HELM without needing to modify HELM code.</p>
<p>There are two steps to adding a custom scenario: adding the custom <code>Scenario</code> subclass, and adding a custom run spec function.</p>
<p>The easiest way to implement the custom <code>Scenario</code> subclass and the custom run spec function would be to copy from an appropriate example and then make the appropriate modifications. Determine the <strong>task</strong> of your scenario, then find the corresponding example <code>Scenario</code> subclass and run spec function from the list below from the <code>simple_scenarios.py</code> and <code>simple_run_specs.py</code> files:</p>
<ul>
<li><strong>Multiple-choice question answering</strong>: <code>SimpleMCQAScenario</code> and <code>get_simple_mcqa_run_spec()</code></li>
<li><strong>Short-answer question answering</strong>: <code>SimpleShortAnswerQAScenario</code> and <code>get_simple_short_answer_qa_run_spec()</code></li>
<li><strong>Open-ended question answering</strong>: This is similar to short-answer question answering, but overlap-based automated metrics may be unsuitable for long generations.</li>
<li><strong>Summarization</strong>: This is similar to short-answer question answering, but overlap-based automated metrics may be unsuitable for long generations.</li>
<li><strong>Multi-class classification</strong>: <code>SimpleClassificationScenario</code> and <code>get_simple_classification_run_spec()</code></li>
<li><strong>Sentiment analysis</strong>: This a sub-type of the Classification task. Set <code>input_noun</code>, <code>output_noun</code> and <code>instructions</code> appropriately.</li>
<li><strong>Toxicity detection</strong>: This a sub-type of the Classification task. Set <code>input_noun</code>, <code>output_noun</code> and <code>instructions</code> appropriately.</li>
<li><strong>Multi-label classification</strong>: This is currently unsupported by HELM.</li>
<li><strong>Named entity recognition</strong>: This is currently unsupported by HELM.</li>
</ul>
<p>If your task is not listed, you may still implement your task using custom adapters and metrics, but there is limited official support for doing so.</p>
<h2 id="custom-scenario-subclass">Custom <code>Scenario</code> subclass</h2>
<p>For this tutorial, we will create a <code>MyScenario</code> class in the the <code>my_scenario</code> module. Make a file called <code>./my_scenario.py</code> under the my_scenario directory. Create a new class called <code>MyScenario</code>. Find the appropriate example scenario and copy its implementation into <code>MyScenario</code>, making sure to also copy all the required imports.</p>
<p>Now we will create a test for the scenario to make sure that it is working correctly. Create a file called <code>./my_scenario_test.py</code> under the my_scenario directory. Create a <code>test_my_scenario()</code> function in this file. Find the appropriate example scenario test from <code>test_simple_scenarios.py</code> and copy its implementation into <code>test_my_scenario()</code>.</p>
<p>You can now run <code>python3 -m pytest test_my_scenario.py</code> to test the example scenario. The test should pass. If you get a <code>ModuleNotFound</code> error, you should set up your <code>PYTHONPATH</code> as explained above, and then try again.</p>
<p>Now, modify <code>MyScenario</code> to include the actual logic to load the instances from your dataset. Modify the test accordingly. Use the test to ensure that your implementation is working.</p>
<h3 id="downloading-data-to-local-disk">Downloading data to local disk</h3>
<p>Frequently, your <code>Scenario</code> will want to download and cache data onto the local disk, rather than downloading it from the internet every time. The <code>output_path</code> argument passed into the <code>get_instances()</code> method will contain a file path to a scenario-specific download folder that you should download these files to. The folder will be under the <code>scenarios</code> subdirectory under the <code>benchmark_output/</code> folder (or the path specified by the <code>--output-path</code> flag for <code>helm-run</code>). You can use the <code>ensure_directory_exists()</code> and <code>ensure_file_downloaded()</code> helper functions to download files, which has the advantage of skipping the download if the file already exists. You can also use set <code>unpack=True</code> in <code>ensure_file_downloaded()</code> to automatically unpack most archive files (e.g. <code>.tar.gz</code> and <code>.zip</code> files).</p>
<p>For examples, refer to:</p>
<ul>
<li><code>gsm_scenario.py</code> - download a JSONL files</li>
<li><code>mmlu_scenario.py</code> - download CSV files</li>
<li><code>narrativeqa_scenario.py</code> - download a zip file containing CSV files</li>
</ul>
<h3 id="working-with-hugging-face-datasets">Working with Hugging Face datasets</h3>
<p>Another frequent use case is downloading data from Hugging Face datasets. You can use <code>load_dataset()</code> to do so. It is recommended that you set the <code>cache_dir</code> parameter to a subdirectory within <code>output_path</code>. This ensures hermeticity by ensuring that the data is downloaded into the scenario-specific download folder.</p>
<p>For an example, refer to:</p>
<ul>
<li><code>math_scenario.py</code></li>
<li><code>legalbench_scenario.py</code></li>
</ul>
<h2 id="custom-run-spec-function">Custom run spec function</h2>
<p>A run spec function is the entry point to the scenario. A run spec function produces a <code>RunSpec</code> (a configuration for an evaluation run). <code>helm-run</code> will run the run spec function to get the <code>RunSpec</code>, and then it will run the evaluation defined by that <code>RunSpec</code>.</p>
<p>HELM will search for modules with names matching these patterns for run spec functions:</p>
<ul>
<li><code>helm.benchmark.run_specs.*_run_specs</code></li>
<li><code>helm_*_run_specs</code> (i.e. a root module)</li>
</ul>
<p>For this tutorial, we will create a <code>get_my_run_spec()</code> function in the <code>helm_my_run_specs</code> module. Under the <code>src/helm/benchmark/scenarios/</code> directory, create a file called <code>helm_my_run_specs.py</code>. Then, create a <code>get_my_run_spec()</code> function in this file and find the appropriate example run spec function from <code>simple_run_specs.py</code> to copy its implementation into <code>get_my_run_spec()</code>. Change the file accordingly to the needs of your scenario.</p>
<p>Now run:</p>
<pre><code>helm-run --run-entries custom:model=openai/gpt2 --suite custom --max-eval-instances 5
</code></pre>
<p>If you get a <code>ValueError: Unknown run spec name</code> error, you should set up your <code>PYTHONPATH</code> as explained above, and then try again.</p>
<h3 id="debugging-with-models">Debugging with models</h3>
<p>The above run entry uses the <code>openai/gpt2</code> model, which is a lightweight model that is reasonably fast, even when using only CPU inference without a GPU.</p>
<p>However, you might want to avoid waiting for model inference when implementing a scenario in order to speed up your iteration times. To do so, you can use the <code>simple/model1</code>, which simply echoes the last word in the prompt. Example <code>helm-run</code> command:</p>
<pre><code>helm-run --run-entries custom:model=simple/model1 --suite custom --max-eval-instances 5
</code></pre>
<p>Note: Both the custom <code>Scenario</code> subclass and the custom run spec function will be added to custom Python modules that have to be importable by Python. The easiest way to do this is to place your custom Python modules under the current working directory and then run <code>export PYTHONPATH=".:$PYTHONPATH"</code> in your shell. Refer to the Importing Custom Modules documentation for other ways to do this.</p>
<h2 id="contributing-your-scenario">Contributing your scenario</h2>
<p>We welcome scenario contributions to HELM if they fit the following criteria:</p>
<ul>
<li>It is commonly-used or notable benchmark (e.g. it has a published paper).</li>
<li>It uses publicly available datasets.</li>
<li>It fills a gap in coverage by HELM's existing scenarios.</li>
</ul>
<p>If your scenario fits this criteria, you should move the files to the conventional HELM locations, and open a pull request. Your <code>*_scenario.py</code> file should be placed in <code>src/helm/benchmark/scenarios/</code> and  your <code>*_run_specs.py</code> file should be placed in <code>src/helm/benchmark/scenarios/</code>. More documentation on the contributor workflow will be added later.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../adding_new_models/" class="btn btn-neutral float-left" title="Adding New Models"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../benchmark/" class="btn btn-neutral float-right" title="Advanced Benchmarking Guide">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/prophetto1/legal-10-benchmark/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../adding_new_models/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../benchmark/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
