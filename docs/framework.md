# Evaluation Architecture

We open-source everything: datasets, harness, scoring, and operational tooling so anyone can reproduce the results.

Legal-10 is built on top of HELM (Holistic Evaluation of Language Models) developed by Stanfard CRFM which provides a unified interface for evaluating both open-weight and closed API models. 

- **unified interface for evaluating both open-weight and closed API models**
- **open-transparency principle**
- **expandable, holistic, grounded in science**

This architecture is an industry specific extension. Our goal is to design benchmarks for th

L10 supplies the legal skill taxonomy, datasets, and scoring rubrics grounded in professional standards. The underlying architecture operates the way we believe legal AI evaluation should work: open, inspectable, reproducible, and resistant to selective reporting.
